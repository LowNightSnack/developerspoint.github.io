<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <title>Introduction To Scikit-Learn | DevelopersPoint</title>
    <meta name="description" content="`Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fittin...">
    
        <meta name="keywords" content="welcome, python, blog, scikit-learn">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Introduction To Scikit-Learn | DevelopersPoint">
    <meta name="twitter:description" content="`Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fittin...">
    <meta property="twitter:image:src" content="https://i.ibb.co/HqmtNGP/banner.png">
    
        <meta name="twitter:site" content="@developerspoint-org">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="http://localhost:4000/Introduction-To-Scikit-learn/">
    <meta property="og:title" content="Introduction To Scikit-Learn | DevelopersPoint">
    <meta property="og:image" content="https://i.ibb.co/HqmtNGP/banner.png">
    <meta property="og:description" content="`Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fittin...">
    <meta property="og:site_name" content="DevelopersPoint | Developers Point">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="DevelopersPoint">
    <meta name="msapplication-TileColor" content="#141414">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="canonical" href="http://localhost:4000/Introduction-To-Scikit-learn/">
    <link rel="alternate" type="application/rss+xml" title="DevelopersPoint | Developers Point" href="http://localhost:4000/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>
</head>

    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/">
            
                DevelopersPoint <span class="version">v3.1.0</span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
        <!--<a href="https://github.com/thiagorossener/jekflix-template" class="get-theme" role="button">
            Get this theme!
        </a>-->
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="http://localhost:4000/">Home</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/about">About</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/feed.xml">Feed</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post two-columns">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2020-11-15T20:30:00+05:30">
                            


November 15, 2020

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>9 min to read</span>
                </p>
                <h1 class="post-title">Introduction To Scikit-Learn</h1>
                <p class="post-subtitle">Welcome to our 1st Blog in Scikit-learn Series</p>

                
                    <img src="https://i.ibb.co/HqmtNGP/banner.png" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <h1 id="introduction">Introduction</h1>

<p>Scikit learn is a machine learning library for python programming language which offers various important features for machine learning such as classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to inter-operate with the python numerical and scientific libraries like <strong>Numpy</strong> and <strong>SciPy</strong>.</p>

<p><img src="https://i.ibb.co/hC8g2qD/scikitlearn.png" alt="alt text" /></p>

<p><em>We will discuss each algorithm and its implementation with codes in detail later in the second part of this series.</em></p>

<h3 id="supervised-algorithms-in-scikit-learn">Supervised Algorithms In Scikit-Learn</h3>

<p>Since you are already familiar with machine learning you already know that there are two types of algorithms i.e supervised and unsupervised algorithms.
So, we will see what scikit-learn has to offer in supervised algorithms.</p>

<p><em>The problem of supervised learning can be broken into two</em> :</p>

<p><img src="https://i.ibb.co/Nngv1M3/diff.png" alt="alt text" /></p>

<p><strong>Classification</strong>: Samples belong to two or more classes, and we want to learn from already labeled data on how to predict the class of unlabeled data. An example would be the handwritten digit recognition example, in which the aim is to assign each input vector to one of a finite number of discrete categories. Another way to think of classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.</p>

<p>Checkout the implementation of the above example:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Standard scientific Python imports
import matplotlib.pyplot as plt

# Import datasets, classifiers and performance metrics
from sklearn import datasets, svm, metrics
from sklearn.model_selection import train_test_split

# The digits dataset
digits = datasets.load_digits()

# The data that we are interested in is made of 8x8 images of digits, let's
# have a look at the first 4 images, stored in the `images` attribute of the
# dataset.  If we were working from image files, we could load them using
# matplotlib.pyplot.imread.  Note that each image must have the same size. For these
# images, we know which digit they represent: it is given in the 'target' of
# the dataset.
_, axes = plt.subplots(2, 4)
images_and_labels = list(zip(digits.images, digits.target))
for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    ax.set_title('Training: %i' % label)

# To apply a classifier on this data, we need to flatten the image, to
# turn the data in a (samples, feature) matrix:
n_samples = len(digits.images)
data = digits.images.reshape((n_samples, -1))

# Create a classifier: a support vector classifier
classifier = svm.SVC(gamma=0.001)

# Split data into train and test subsets
X_train, X_test, y_train, y_test = train_test_split(
    data, digits.target, test_size=0.5, shuffle=False)

# We learn the digits on the first half of the digits
classifier.fit(X_train, y_train)

# Now predict the value of the digit on the second half:
predicted = classifier.predict(X_test)

images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))
for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    ax.set_title('Prediction: %i' % prediction)

print("Classification report for classifier %s:\n%s\n"
      % (classifier, metrics.classification_report(y_test, predicted)))
disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)
disp.figure_.suptitle("Confusion Matrix")
print("Confusion matrix:\n%s" % disp.confusion_matrix)

plt.show()
</code></pre></div></div>

<p><strong>Output:</strong>
    accuracy                           0.97       899
   macro avg       0.97      0.97      0.97       899
weighted avg       0.97      0.97      0.97       899</p>

<p><img src="https://i.ibb.co/CHtG3qp/handwritten.png" alt="alt text" /></p>

<p><strong>Regression</strong>: If the desired output consists of one or more continuous variables, then the task is called regression. An example of a regression problem would be the prediction of the diabetes in which input consist of the age, sex, body mass index, average blood pressure, etc.</p>

<p>Checkout the implementation of the above example:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

# Use only one feature
diabetes_X = diabetes_X[:, np.newaxis, 2]

# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]

# Split the targets into training/testing sets
diabetes_y_train = diabetes_y[:-20]
diabetes_y_test = diabetes_y[-20:]

# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = regr.predict(diabetes_X_test)

# The coefficients
print('Coefficients: \n', regr.coef_)
# The mean squared error
print('Mean squared error: %.2f'
      % mean_squared_error(diabetes_y_test, diabetes_y_pred))
# The coefficient of determination: 1 is perfect prediction
print('Coefficient of determination: %.2f'
      % r2_score(diabetes_y_test, diabetes_y_pred))

# Plot outputs
plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')
plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)

plt.xticks(())
plt.yticks(())

plt.show()
</code></pre></div></div>
<p><em><strong>Output:</strong></em>
Coefficients: 
 [938.23786125]
Mean squared error: 2548.07
Coefficient of determination: 0.47
<img src="https://i.ibb.co/LQmy09V/diabetes.png" alt="alt text" />
<em><strong>It’s okay if you don’t understand the code, we will be discussing it in detail later.</strong></em></p>

<h4 id="scikit-learn-supports-following-models-">Scikit Learn supports following models :</h4>
<ul>
  <li>Generalized Linear Models</li>
  <li>Kernel ridge regression</li>
  <li>Support Vector Machines</li>
  <li>Stochastic Gradient Descent</li>
  <li>Linear and Quadratic Discriminant Analysis</li>
  <li>Naive Bayes</li>
  <li>Decision Trees</li>
  <li>Ensemble methods</li>
  <li>Multiclass and multilabel algorithms</li>
  <li>Feature selection</li>
  <li>Nearest Neighbors</li>
  <li>Gaussian Processes</li>
  <li>Cross decomposition</li>
  <li>Semi-Supervised</li>
  <li>Isotonic regression</li>
  <li>Probability calibration</li>
  <li>Neural network models (supervised)</li>
</ul>

<h3 id="unsupervised-algorithms-in-scikit-learn">Unsupervised Algorithms In Scikit-Learn</h3>

<p>Now, let us see what scikit learn offers us in unsupervised algorithms.</p>

<p><img src="https://i.ibb.co/sPGCVhB/cluster1.png" alt="alt text" /></p>

<p>In this the training data consists of a set of input vectors without any corresponding target values/labels. The goal in such problems is to discover groups of similar data within the data, where it is called <strong>clustering</strong>.</p>

<p>Checkout the implementation of K-means clustering on Handwritten digits example:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from time import time
import numpy as np
import matplotlib.pyplot as plt

from sklearn import metrics
from sklearn.cluster import KMeans
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale

np.random.seed(42)

X_digits, y_digits = load_digits(return_X_y=True)
data = scale(X_digits)

n_samples, n_features = data.shape
n_digits = len(np.unique(y_digits))
labels = y_digits

sample_size = 300

print("n_digits: %d, \t n_samples %d, \t n_features %d"
      % (n_digits, n_samples, n_features))


print(82 * '_')
print('init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette')


def bench_k_means(estimator, name, data):
    t0 = time()
    estimator.fit(data)
    print('%-9s\t%.2fs\t%i\t%.3f\t%.3f\t%.3f\t%.3f\t%.3f\t%.3f'
          % (name, (time() - t0), estimator.inertia_,
             metrics.homogeneity_score(labels, estimator.labels_),
             metrics.completeness_score(labels, estimator.labels_),
             metrics.v_measure_score(labels, estimator.labels_),
             metrics.adjusted_rand_score(labels, estimator.labels_),
             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),
             metrics.silhouette_score(data, estimator.labels_,
                                      metric='euclidean',
                                      sample_size=sample_size)))

bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),
              name="k-means++", data=data)

bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),
              name="random", data=data)

# in this case the seeding of the centers is deterministic, hence we run the
# kmeans algorithm only once with n_init=1
pca = PCA(n_components=n_digits).fit(data)
bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),
              name="PCA-based",
              data=data)
print(82 * '_')

# #############################################################################
# Visualize the results on PCA-reduced data

reduced_data = PCA(n_components=2).fit_transform(data)
kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)
kmeans.fit(reduced_data)

# Step size of the mesh. Decrease to increase the quality of the VQ.
h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].

# Plot the decision boundary. For that, we will assign a color to each
x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1
y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# Obtain labels for each point in mesh. Use last trained model.
Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])

# Put the result into a color plot
Z = Z.reshape(xx.shape)
plt.figure(1)
plt.clf()
plt.imshow(Z, interpolation='nearest',
           extent=(xx.min(), xx.max(), yy.min(), yy.max()),
           cmap=plt.cm.Paired,
           aspect='auto', origin='lower')

plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)
# Plot the centroids as a white X
centroids = kmeans.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1],
            marker='x', s=169, linewidths=3,
            color='w', zorder=10)
plt.title('K-means clustering on the digits dataset (PCA-reduced data)\n'
          'Centroids are marked with white cross')
plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.xticks(())
plt.yticks(())
plt.show()
</code></pre></div></div>
<p><em><strong>Output:</strong></em>
n_digits: 10,    n_samples 1797,   n_features 64
<strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__
init    time  inertia homo  compl v-meas  ARI AMI silhouette
k-means++ 0.40s 69510 0.610 0.657 0.633 0.481 0.629 0.129
random    0.30s 69907 0.633 0.674 0.653 0.518 0.649 0.131
PCA-based 0.05s 70768 0.668 0.695 0.681 0.558 0.678 0.142
__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong><strong>__</strong>
<img src="https://i.ibb.co/JRSKmVB/cluster.png" alt="alt text" />
<em><strong>It’s okay if you don’t understand the code, we will be discussing it in detail later.</strong></em></p>

<h5 id="scikit-learn-supports-these-models-">Scikit Learn supports these models :</h5>

<ul>
  <li>Gaussian mixture models</li>
  <li>Decomposing signals in components (matrix factorization problems)</li>
  <li>Covariance estimation</li>
  <li>Novelty and Outlier Detection</li>
  <li>Manifold learning</li>
  <li>Clustering</li>
  <li>Biclustering</li>
  <li>Density Estimation</li>
  <li>Neural network models (unsupervised).</li>
</ul>

<h3 id="model-selection-and-evaluation">Model Selection and Evaluation</h3>

<p>As we know learning the parameters of a prediction function and testing it on the same data is a methodological mistake or it can be called as cheating : a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called <strong>overfitting</strong>. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test.</p>

<p><img src="https://i.ibb.co/crBq87g/model.png" alt="alt text" /></p>

<p><em>The above image shows three cases underfitting, ideal and overfitting scenarios respectively.</em></p>

<h4 id="model-selection-contains-the-following-">Model selection contains the following :</h4>
<ul>
  <li>Cross-validation: evaluating estimator performance</li>
  <li>Tuning the hyper-parameters of an estimator</li>
  <li>Model evaluation: quantifying the quality of predictions</li>
  <li>Model persistence</li>
  <li>Validation curves: plotting scores to evaluate models</li>
</ul>

<h3 id="dataset-transformations">Dataset transformations</h3>

<p>These are represented by classes with a fit method, which learns model parameters (e.g. mean and standard deviation for normalization) from a training set, and a transform method which applies this transformation model to unseen data. fit_transform may be a more convenient and efficient for modelling and transforming the training data simultaneously.</p>

<p>It has following sub-categories :</p>
<ul>
  <li>Pipeline and FeatureUnion: combining estimators</li>
  <li>Feature extraction</li>
  <li>Preprocessing data</li>
  <li>Unsupervised dimensionality reduction</li>
  <li>Random Projection</li>
  <li>Kernel Approximation</li>
  <li>Pairwise metrics, Affinities and Kernels</li>
  <li>Transforming the prediction target (y)</li>
</ul>

<h3 id="dataset-loading-utilities">Dataset Loading Utilities</h3>

<p>The <code class="language-plaintext highlighter-rouge">sklearn.datasets</code> package embeds some small yet useful datasets.</p>

<ul>
  <li>The Olivetti faces dataset</li>
  <li>The 20 newsgroups text dataset</li>
  <li>Downloading datasets from the mldata.org repository</li>
  <li>The Labeled Faces in the Wild face recognition dataset</li>
  <li>Forest covertypes</li>
  <li>RCV1 dataset</li>
  <li>Boston House Prices dataset</li>
  <li>Breast Cancer Wisconsin (Diagnostic) Database</li>
  <li>Diabetes dataset</li>
  <li>Optical Recognition of Handwritten Digits Data Set</li>
  <li>Iris Plants Database
<em>and many more..</em></li>
</ul>

<h3 id="resources">Resources</h3>

<ul>
  <li><a href="https://scikit-learn.org/">scikit-learn documentation</a></li>
  <li><a href="https://github.com/scikit-learn/scikit-learn">scikit-learn Repository</a></li>
</ul>

<h3 id="continued-in-next-week">Continued in next Week….</h3>
<p>This was a brief intro of what we will be discussing in next few weeks, stay tunned..</p>


                <!-- Pagination links -->


            </article>

            
                <aside class="see-also">
                    <h2>See also</h2>
                    <ul>
                        
                        
                        
                            <li>
                                <a href="/Introduction-To-NumPy/">
                                    
                                        <img src="/assets/img/numpyintro.png">
                                    
                                    <h3>Introduction To Numpy</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/Introduction-To-Pandas/">
                                    
                                        <img src="http://blog.developerspoint.org/assets/img/pandas_intro.png">
                                    
                                    <h3>Introduction To Pandas</h3>
                                </a>
                            </li>
                        
                    </ul>
                </aside>
            

        </section>

        <!-- Add time bar only for pages without pagination -->
        
            <div class="time-bar" data-minutes="9">
    <span class="time-completed"></span>
    <span class="time-remaining"></span>
    <div class="bar">
        <span class="completed" style="width:0%;"></span>
        <span class="remaining" style="width:100%;"></span>
    </div>
</div>

            <div class="recommendation">
    <div class="message">
        <strong>Why don't you read something next?</strong>
        <div>
            <button>
                <svg><use xlink:href="#icon-arrow-right"></use></svg>
                <span>Go back to top</span>
            </button>
        </div>
    </div>
    
    <a href="/Introduction-To-NumPy/" class="post-preview">
        <div class="image">
            
                <img src="/assets/img/numpyintro.png">
            
        </div>
        <h3 class="title">Introduction To Numpy</h3>
    </a>
</div>

        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;`Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.&quot;%20http://localhost:4000/Introduction-To-Scikit-learn/%20via%20&#64;developerspoint-org&hashtags=welcome,python,blog,scikit-learn,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/Introduction-To-Scikit-learn/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
</section>

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="https://i.ibb.co/cvN0Tsf/20201114-235057.jpg" alt="Ketan Bansal">
      
      <p class="def">Author</p>
      <h3 class="name">
        <a href="/authors/KetanBansal/">Ketan Bansal</a>
      </h3>
      <p class="desc">Machine Learning enthusiast</p>
      <p>
        
          <a href="https://github.com/ketan-b" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
          <a href="https://www.facebook.com/ketan.bansal.319" title="Facebook">
            <svg><use xlink:href="#icon-facebook"></use></svg>
          </a>
        
        
        
          <a href="https://medium.com/@ketan255" title="Medium">
            <svg><use xlink:href="#icon-medium"></use></svg>
          </a>
        
        
          <a href="https://www.instagram.com/ketan_255" title="Instagram">
            <svg><use xlink:href="#icon-instagram"></use></svg>
          </a>
        
        
          <a href="https://www.linkedin.com/in/ketan-bansal-894021191/" title="LinkedIn">
            <svg><use xlink:href="#icon-linkedin"></use></svg>
          </a>
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Ketan Bansal",
      
      "image": "https://i.ibb.co/cvN0Tsf/20201114-235057.jpg",
      
      "jobTitle": "Chief Editor",
      "url": "http://localhost:4000/authors/KetanBansal/",
      "sameAs": [
        "https://github.com/ketan-b","https://www.facebook.com/ketan.bansal.319","https://medium.com/@ketan255","https://www.instagram.com/ketan_255","https://www.linkedin.com/in/ketan-bansal-894021191/"
      ]
  }
  </script>


        

<section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = false;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = 'https-blog-developerspoint-org';
        var disqus_title = '';
        var disqus_url = '/Introduction-To-Scikit-learn/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>



        <footer>
    <p>
      
        <a href="https://github.com/developerspoint-org" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
        <a href="https://www.facebook.com/developerspoint-org" title="Facebook">
          <svg><use xlink:href="#icon-facebook"></use></svg>
        </a>
      
      
        <a href="https://twitter.com/developerspoint-org" title="Twitter">
          <svg><use xlink:href="#icon-twitter"></use></svg>
        </a>
      
      
        <a href="https://medium.com/@developerspoint-org" title="Medium">
          <svg><use xlink:href="#icon-medium"></use></svg>
        </a>
      
      
        <a href="https://www.instagram.com/developerspoint-org" title="Instagram">
          <svg><use xlink:href="#icon-instagram"></use></svg>
        </a>
      
      
        <a href="https://www.linkedin.com/in/developerspoint-org" title="LinkedIn">
          <svg><use xlink:href="#icon-linkedin"></use></svg>
        </a>
      
    </p>

    <ul>
  
    
      <li>
        <a href="http://localhost:4000/">Home</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/about">About</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="http://localhost:4000/feed.xml">Feed</a>
      </li>
    
  
</ul>


    <p>
      <span>DevelopersPoint Blog</span> was made with <svg class="love"><use xlink:href="#icon-heart"></use></svg> by <a href="https://www.developerspoint.org" target="_blank" class="creator">DevelopersPoint</a>
    </p>
</footer>









<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "DevelopersPoint",
  "description": "DevelopersPoint is an open source student run club",
  "url": "http://localhost:4000/",
  "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:4000/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/developerspoint-org","https://www.facebook.com/developerspoint-org","https://twitter.com/developerspoint-org","https://medium.com/@developerspoint-org","https://www.instagram.com/developerspoint-org","https://www.linkedin.com/in/developerspoint-org"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZDW4M02W4C"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ZDW4M02W4C');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "Introduction To Scikit-Learn",
            "headline": "Welcome to our 1st Blog in Scikit-learn Series",
            "description": "`Scikit-learn` is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.",
            "image": "https://i.ibb.co/HqmtNGP/banner.png",
            "url": "http://localhost:4000/Introduction-To-Scikit-learn/",
            "articleBody": "Introduction

Scikit learn is a machine learning library for python programming language which offers various important features for machine learning such as classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to inter-operate with the python numerical and scientific libraries like Numpy and SciPy.



We will discuss each algorithm and its implementation with codes in detail later in the second part of this series.

Supervised Algorithms In Scikit-Learn

Since you are already familiar with machine learning you already know that there are two types of algorithms i.e supervised and unsupervised algorithms.
So, we will see what scikit-learn has to offer in supervised algorithms.

The problem of supervised learning can be broken into two :



Classification: Samples belong to two or more classes, and we want to learn from already labeled data on how to predict the class of unlabeled data. An example would be the handwritten digit recognition example, in which the aim is to assign each input vector to one of a finite number of discrete categories. Another way to think of classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.

Checkout the implementation of the above example:
# Standard scientific Python imports
import matplotlib.pyplot as plt

# Import datasets, classifiers and performance metrics
from sklearn import datasets, svm, metrics
from sklearn.model_selection import train_test_split

# The digits dataset
digits = datasets.load_digits()

# The data that we are interested in is made of 8x8 images of digits, let's
# have a look at the first 4 images, stored in the `images` attribute of the
# dataset.  If we were working from image files, we could load them using
# matplotlib.pyplot.imread.  Note that each image must have the same size. For these
# images, we know which digit they represent: it is given in the 'target' of
# the dataset.
_, axes = plt.subplots(2, 4)
images_and_labels = list(zip(digits.images, digits.target))
for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    ax.set_title('Training: %i' % label)

# To apply a classifier on this data, we need to flatten the image, to
# turn the data in a (samples, feature) matrix:
n_samples = len(digits.images)
data = digits.images.reshape((n_samples, -1))

# Create a classifier: a support vector classifier
classifier = svm.SVC(gamma=0.001)

# Split data into train and test subsets
X_train, X_test, y_train, y_test = train_test_split(
    data, digits.target, test_size=0.5, shuffle=False)

# We learn the digits on the first half of the digits
classifier.fit(X_train, y_train)

# Now predict the value of the digit on the second half:
predicted = classifier.predict(X_test)

images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))
for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    ax.set_title('Prediction: %i' % prediction)

print(&quot;Classification report for classifier %s:\n%s\n&quot;
      % (classifier, metrics.classification_report(y_test, predicted)))
disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)
disp.figure_.suptitle(&quot;Confusion Matrix&quot;)
print(&quot;Confusion matrix:\n%s&quot; % disp.confusion_matrix)

plt.show()


Output:
    accuracy                           0.97       899
   macro avg       0.97      0.97      0.97       899
weighted avg       0.97      0.97      0.97       899



Regression: If the desired output consists of one or more continuous variables, then the task is called regression. An example of a regression problem would be the prediction of the diabetes in which input consist of the age, sex, body mass index, average blood pressure, etc.

Checkout the implementation of the above example:
import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score

# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

# Use only one feature
diabetes_X = diabetes_X[:, np.newaxis, 2]

# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]

# Split the targets into training/testing sets
diabetes_y_train = diabetes_y[:-20]
diabetes_y_test = diabetes_y[-20:]

# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = regr.predict(diabetes_X_test)

# The coefficients
print('Coefficients: \n', regr.coef_)
# The mean squared error
print('Mean squared error: %.2f'
      % mean_squared_error(diabetes_y_test, diabetes_y_pred))
# The coefficient of determination: 1 is perfect prediction
print('Coefficient of determination: %.2f'
      % r2_score(diabetes_y_test, diabetes_y_pred))

# Plot outputs
plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')
plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)

plt.xticks(())
plt.yticks(())

plt.show()

Output:
Coefficients: 
 [938.23786125]
Mean squared error: 2548.07
Coefficient of determination: 0.47

It’s okay if you don’t understand the code, we will be discussing it in detail later.

Scikit Learn supports following models :

  Generalized Linear Models
  Kernel ridge regression
  Support Vector Machines
  Stochastic Gradient Descent
  Linear and Quadratic Discriminant Analysis
  Naive Bayes
  Decision Trees
  Ensemble methods
  Multiclass and multilabel algorithms
  Feature selection
  Nearest Neighbors
  Gaussian Processes
  Cross decomposition
  Semi-Supervised
  Isotonic regression
  Probability calibration
  Neural network models (supervised)


Unsupervised Algorithms In Scikit-Learn

Now, let us see what scikit learn offers us in unsupervised algorithms.



In this the training data consists of a set of input vectors without any corresponding target values/labels. The goal in such problems is to discover groups of similar data within the data, where it is called clustering.

Checkout the implementation of K-means clustering on Handwritten digits example:
from time import time
import numpy as np
import matplotlib.pyplot as plt

from sklearn import metrics
from sklearn.cluster import KMeans
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale

np.random.seed(42)

X_digits, y_digits = load_digits(return_X_y=True)
data = scale(X_digits)

n_samples, n_features = data.shape
n_digits = len(np.unique(y_digits))
labels = y_digits

sample_size = 300

print(&quot;n_digits: %d, \t n_samples %d, \t n_features %d&quot;
      % (n_digits, n_samples, n_features))


print(82 * '_')
print('init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette')


def bench_k_means(estimator, name, data):
    t0 = time()
    estimator.fit(data)
    print('%-9s\t%.2fs\t%i\t%.3f\t%.3f\t%.3f\t%.3f\t%.3f\t%.3f'
          % (name, (time() - t0), estimator.inertia_,
             metrics.homogeneity_score(labels, estimator.labels_),
             metrics.completeness_score(labels, estimator.labels_),
             metrics.v_measure_score(labels, estimator.labels_),
             metrics.adjusted_rand_score(labels, estimator.labels_),
             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),
             metrics.silhouette_score(data, estimator.labels_,
                                      metric='euclidean',
                                      sample_size=sample_size)))

bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),
              name=&quot;k-means++&quot;, data=data)

bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),
              name=&quot;random&quot;, data=data)

# in this case the seeding of the centers is deterministic, hence we run the
# kmeans algorithm only once with n_init=1
pca = PCA(n_components=n_digits).fit(data)
bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),
              name=&quot;PCA-based&quot;,
              data=data)
print(82 * '_')

# #############################################################################
# Visualize the results on PCA-reduced data

reduced_data = PCA(n_components=2).fit_transform(data)
kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)
kmeans.fit(reduced_data)

# Step size of the mesh. Decrease to increase the quality of the VQ.
h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].

# Plot the decision boundary. For that, we will assign a color to each
x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1
y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# Obtain labels for each point in mesh. Use last trained model.
Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])

# Put the result into a color plot
Z = Z.reshape(xx.shape)
plt.figure(1)
plt.clf()
plt.imshow(Z, interpolation='nearest',
           extent=(xx.min(), xx.max(), yy.min(), yy.max()),
           cmap=plt.cm.Paired,
           aspect='auto', origin='lower')

plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)
# Plot the centroids as a white X
centroids = kmeans.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1],
            marker='x', s=169, linewidths=3,
            color='w', zorder=10)
plt.title('K-means clustering on the digits dataset (PCA-reduced data)\n'
          'Centroids are marked with white cross')
plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.xticks(())
plt.yticks(())
plt.show()

Output:
n_digits: 10,    n_samples 1797,   n_features 64
____________________________
init    time  inertia homo  compl v-meas  ARI AMI silhouette
k-means++ 0.40s 69510 0.610 0.657 0.633 0.481 0.629 0.129
random    0.30s 69907 0.633 0.674 0.653 0.518 0.649 0.131
PCA-based 0.05s 70768 0.668 0.695 0.681 0.558 0.678 0.142
____________________________

It’s okay if you don’t understand the code, we will be discussing it in detail later.

Scikit Learn supports these models :


  Gaussian mixture models
  Decomposing signals in components (matrix factorization problems)
  Covariance estimation
  Novelty and Outlier Detection
  Manifold learning
  Clustering
  Biclustering
  Density Estimation
  Neural network models (unsupervised).


Model Selection and Evaluation

As we know learning the parameters of a prediction function and testing it on the same data is a methodological mistake or it can be called as cheating : a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test.



The above image shows three cases underfitting, ideal and overfitting scenarios respectively.

Model selection contains the following :

  Cross-validation: evaluating estimator performance
  Tuning the hyper-parameters of an estimator
  Model evaluation: quantifying the quality of predictions
  Model persistence
  Validation curves: plotting scores to evaluate models


Dataset transformations

These are represented by classes with a fit method, which learns model parameters (e.g. mean and standard deviation for normalization) from a training set, and a transform method which applies this transformation model to unseen data. fit_transform may be a more convenient and efficient for modelling and transforming the training data simultaneously.

It has following sub-categories :

  Pipeline and FeatureUnion: combining estimators
  Feature extraction
  Preprocessing data
  Unsupervised dimensionality reduction
  Random Projection
  Kernel Approximation
  Pairwise metrics, Affinities and Kernels
  Transforming the prediction target (y)


Dataset Loading Utilities

The sklearn.datasets package embeds some small yet useful datasets.


  The Olivetti faces dataset
  The 20 newsgroups text dataset
  Downloading datasets from the mldata.org repository
  The Labeled Faces in the Wild face recognition dataset
  Forest covertypes
  RCV1 dataset
  Boston House Prices dataset
  Breast Cancer Wisconsin (Diagnostic) Database
  Diabetes dataset
  Optical Recognition of Handwritten Digits Data Set
  Iris Plants Database
and many more..


Resources


  scikit-learn documentation
  scikit-learn Repository


Continued in next Week….
This was a brief intro of what we will be discussing in next few weeks, stay tunned..
",
            "wordcount": "1646",
            "inLanguage": "en",
            "dateCreated": "2020-11-15/",
            "datePublished": "2020-11-15/",
            "dateModified": "2020-11-15/",
            "author": {
                "@type": "Person",
                "name": "Ketan Bansal",
                
                "image": "https://i.ibb.co/cvN0Tsf/20201114-235057.jpg",
                
                "jobTitle": "Chief Editor",
                "url": "http://localhost:4000/authors/KetanBansal/",
                "sameAs": [
                    "https://github.com/ketan-b","https://www.facebook.com/ketan.bansal.319","https://medium.com/@ketan255","https://www.instagram.com/ketan_255","https://www.linkedin.com/in/ketan-bansal-894021191/"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "DevelopersPoint",
                "url": "http://localhost:4000/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "http://localhost:4000/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "blog",
            "articleSection": "blog",
            "keywords": ["welcome","python","blog","scikit-learn"]
        }
        </script>
    </body>
</html>
